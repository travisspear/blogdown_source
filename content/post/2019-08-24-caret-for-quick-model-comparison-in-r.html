---
title: Caret for Quick Model Comparison in R
author: ~
date: '2019-08-24'
slug: caret-for-quick-model-comparison-in-r
categories: []
tags: []
comments: no
images: ~
---

<script src="/rmarkdown-libs/kePrint/kePrint.js"></script>


<p>R has hundreds, if not thousands, of packages providing access to machine learning algorithms. With the variety of naming conventions, function requirements, and output structures provided throughout these packages comparing results can become a nuisance. To streamline the process of testing and comparing models from many R packages, the caret package provides an interface to over 500 popular algorithms aggregated from across the R community.</p>
<p>To demonstrate the ease of testing and comparing multiple model types, I will revisit the Titanic dataset to predict passenger survival using 5 common algorithm types and then create an ensemble model with the outputs.</p>
<div id="workspace-set-up" class="section level2">
<h2>Workspace Set Up</h2>
<pre class="r"><code>#### Set Up ----
library(tidyverse) # For general data manipulation and ggplot
library(caret) # For all of the machine learning algorithms

# Load the data
train &lt;- read.csv(&quot;../../content/post/data/train.csv&quot;)

# Check for issues before you begin modeling: Remove/Impute NA values, Prune Unnecessary Columns, Ensure proper data types
colSums(is.na(train))
sapply(train, class)

#### Removing NA Values
train &lt;- train %&gt;%
  # Fix NA Age values
  group_by(Pclass, Sex, Embarked) %&gt;%
  mutate(
    Age = ifelse(is.na(Age), mean(Age, na.rm = T), Age)
  ) %&gt;%
  ungroup %&gt;% # Remove grouping used for mean ages
  # Fix NA Embarked values
  mutate(
    Embarked = ifelse(is.na(Embarked), names(sort(table(train$Embarked), decreasing = T)[1]), Embarked) %&gt;%
      as.factor()
  ) %&gt;%
  mutate(Survived = as.factor(Survived)) %&gt;%
  select(Pclass, Sex, Age, SibSp, Parch, Fare, Embarked, Survived)


# Recheck NA counts and value types
colSums(is.na(train))
sapply(train, class)</code></pre>
</div>
<div id="modeling" class="section level2">
<h2>Modeling</h2>
<div id="creating-data-subsets" class="section level4">
<h4>Creating Data Subsets</h4>
<p>Using the labeled training titanic dataset, split this further into training (t1) and testing (t2) subsets which will both now contain survival labels.</p>
<pre class="r"><code>set.seed(1)
tSplit &lt;- sample(1:nrow(train), .7*nrow(train))
t1 &lt;- train[tSplit,]
t2 &lt;- train[-tSplit,]</code></pre>
</div>
<div id="caret-training-controls" class="section level4">
<h4>Caret Training Controls</h4>
<p>Models will be evaluated using reapeated cross validation and random hyper-parameter tuning.</p>
<pre class="r"><code>fitControl &lt;- trainControl(
  method = &quot;repeatedcv&quot;, 
  number = 10, 
  repeats = 3, 
  search = &quot;random&quot;
)</code></pre>
</div>
<div id="the-five-models" class="section level4">
<h4>The Five Models</h4>
<p>Predictions and Confusion Matrices will be generated from the following five model types:
* Generalized Linear Model<br />
* Conditional Inference Tree<br />
* Gradient Boosting<br />
* Randomforest<br />
* Neural Net</p>
<pre class="r"><code>set.seed(1)

#### Logistic Regression ----
mod_logReg &lt;- train(
  Survived ~ .,
  data = t1,
  method= &quot;glm&quot;,
  family = &quot;binomial&quot;,
  trControl = fitControl
)

pred_logReg &lt;- predict(mod_logReg, newdata=t2)
conf_logReg &lt;- confusionMatrix(data=pred_logReg, t2$Survived)


#### Decision Tree ----
mod_dTree &lt;- train(
  Survived ~ .,
  data = t1,
  method= &quot;ctree&quot;,
  trControl = fitControl
)

pred_dTree &lt;- predict(mod_dTree, newdata=t2)
conf_dTree &lt;- confusionMatrix(data=pred_dTree, t2$Survived)


#### GBM ----
mod_GBM &lt;- train(
  Survived ~ .,
  data = t1,
  method= &quot;gbm&quot;,
  trControl = fitControl
)

pred_GBM &lt;- predict(mod_GBM, newdata=t2)
conf_GBM &lt;- confusionMatrix(data=pred_GBM, t2$Survived)


#### Random Forest ----
mod_RF &lt;- train(
  Survived ~ .,
  data = t1,
  method= &quot;rf&quot;,
  trControl = fitControl,
  tuneLength = 15
)

pred_RF &lt;- predict(mod_RF, newdata=t2)
conf_RF &lt;- confusionMatrix(data=pred_RF, t2$Survived)


#### Neural Net ----
mod_NNet &lt;- train(
  Survived ~ .,
  data = t1,
  method= &quot;nnet&quot;,
  trControl = fitControl,
  trace = TRUE,
  maxit = 100,
  lineout = 1
)

pred_NNet &lt;- predict(mod_NNet, newdata=t2)
conf_NNet &lt;- confusionMatrix(data=pred_NNet, t2$Survived)</code></pre>
</div>
<div id="ensemble" class="section level4">
<h4>Ensemble</h4>
<p>Majority voting of model results will be used for ensembling. In other words, the most common outcome (0/Died, 1/Survived) will be chosen in the ensemble model based on the output of the previous five models.</p>
<pre class="r"><code>#### Ensemble ----
majority &lt;- data.frame(
  actual = t2$Survived,
  logReg = pred_logReg,
  dTree = pred_dTree,
  GBM = pred_GBM,
  RF = pred_RF,
  NNet = pred_NNet
) %&gt;%
  mutate(
    Majority = round((as.numeric(levels(logReg))[logReg] + as.numeric(levels(dTree))[dTree] + as.numeric(levels(GBM))[GBM] + as.numeric(levels(RF))[RF] + as.numeric(levels(NNet))[NNet])/5, 0) %&gt;%
      as.factor
  )

conf_majority &lt;- confusionMatrix(data = majority$Majority, reference = t2$Survived)</code></pre>
</div>
</div>
<div id="model-evaluation" class="section level2">
<h2>Model Evaluation</h2>
<table class="table table-striped" style="margin-left: auto; margin-right: auto;">
<thead>
<tr>
<th style="text-align:left;">
ModelType
</th>
<th style="text-align:right;">
Accuracy
</th>
<th style="text-align:right;">
F1
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
Logistic Regression
</td>
<td style="text-align:right;">
0.813
</td>
<td style="text-align:right;">
0.855
</td>
</tr>
<tr>
<td style="text-align:left;">
Decision Tree
</td>
<td style="text-align:right;">
0.821
</td>
<td style="text-align:right;">
0.856
</td>
</tr>
<tr>
<td style="text-align:left;">
Gradient Boosting
</td>
<td style="text-align:right;">
0.776
</td>
<td style="text-align:right;">
0.825
</td>
</tr>
<tr>
<td style="text-align:left;">
Random Forest
</td>
<td style="text-align:right;">
0.843
</td>
<td style="text-align:right;">
0.879
</td>
</tr>
<tr>
<td style="text-align:left;">
Neural Net
</td>
<td style="text-align:right;">
0.832
</td>
<td style="text-align:right;">
0.868
</td>
</tr>
<tr>
<td style="text-align:left;">
Ensemble
</td>
<td style="text-align:right;">
0.828
</td>
<td style="text-align:right;">
0.865
</td>
</tr>
</tbody>
</table>
<p><img src="/post/2019-08-24-caret-for-quick-model-comparison-in-r_files/figure-html/evaluation-1.png" width="672" /></p>
</div>
